{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"ARTSTUTORIAL.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"a73qmKPUbFys"},"source":["#Prequisite"]},{"cell_type":"code","metadata":{"id":"U09O7JDwZnZ2"},"source":["# !pip install opencv-python==4.5.1.48\n","!pip install mediapipe==0.8.3"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JlSn4Y5v0pgv"},"source":["#Train"]},{"cell_type":"markdown","metadata":{"id":"SZ5mCvUAiBGv"},"source":["download repository"]},{"cell_type":"code","metadata":{"id":"jD2rOtIBiLaA"},"source":["!git clone  https://github.com/4-geeks/ARTS.git"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uVpghzjTjdrS"},"source":["download & unzip dataset for train"]},{"cell_type":"code","metadata":{"id":"iCoWh6E4jdWy"},"source":["!gdown https://drive.google.com/u/2/uc?id=1mTcz4jYpScHwOwGnvBerZDzZzJhRIXGS&export=download\n","!unzip /content/sit_up.zip -d /content"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gXM4zHjKkuTv"},"source":["train data and get csv for each terminal"]},{"cell_type":"code","metadata":{"id":"E6z-WBza0x05","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1622300756411,"user_tz":-270,"elapsed":42589,"user":{"displayName":"MMM PPP","photoUrl":"","userId":"02873965013139778500"}},"outputId":"cc434c97-e7f2-420e-aefc-f0f5ded51b15"},"source":["%cd /content\n","from ARTS.config import createcsv\n","\n","bootstrap_images_in_folder = '/content/sit_up'\n","bootstrap_csvs_out_folder = 'situp_poses_csvs_out'\n","bootstrap_images_out_folder = 'situp_poses_images_out'\n","csv=createcsv(bootstrap_images_in_folder,bootstrap_images_out_folder,bootstrap_csvs_out_folder)\n","csv.creat()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Bootstrapping  sit\n","\r  0%|          | 0/123 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["/content\n","Number of images per pose class:\n","  sit: 123\n","  up: 133\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 123/123 [00:20<00:00,  5.89it/s]\n","Bootstrapping  up\n","100%|██████████| 133/133 [00:21<00:00,  6.22it/s]\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"5fD2qEvCW0t2"},"source":["bootstrap_images_in_folder is the address of images file.\n","\n","bootstrap_csvs_out_folder is the address of generated csv file.\n","\n","bootstrap_images_out_folder is the address of generated pose estimation images file."]},{"cell_type":"markdown","metadata":{"id":"nyLdXtLda7UM"},"source":["#Inference"]},{"cell_type":"markdown","metadata":{"id":"76VBw0IGlff3"},"source":["download video for test"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"W9JWEI0el8Ks","executionInfo":{"status":"ok","timestamp":1622299861935,"user_tz":-270,"elapsed":1499,"user":{"displayName":"MMM PPP","photoUrl":"","userId":"02873965013139778500"}},"outputId":"29ec62dd-8af9-41bb-cf86-139f64ddf311"},"source":["!gdown https://drive.google.com/u/2/uc?id=1axNpIw_Dbpq2ObrLtZMAss23G3zDo-UE&export=download"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Downloading...\n","From: https://drive.google.com/u/2/uc?id=1axNpIw_Dbpq2ObrLtZMAss23G3zDo-UE\n","To: /content/sit_up.mp4\n","\r0.00B [00:00, ?B/s]\r2.27MB [00:00, 67.1MB/s]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"_PMCgCucll3o"},"source":["run below code and get result"]},{"cell_type":"code","metadata":{"id":"DASBnrSxbL6V"},"source":["from matplotlib import pyplot as plt\n","import cv2\n","from ARTS.config import Observer\n","video_path = '/content/sit_up.mp4'\n","pose_samples_folder = '/content/situp_poses_csvs_out'\n","%cd /content/\n","video_cap = cv2.VideoCapture(video_path)\n","fps = video_cap.get(cv2.CAP_PROP_FPS)\n","DIC_ACT={'act1':['sit','up']}\n","obsrvr=Observer(pose_samples_folder,fps,DIC_ACT)\n","nm=obsrvr.name\n","\n","while True:\n","  success, input_frame = video_cap.read()\n","  if not success:\n","    break\n","  obsrvr.update(input_frame,second=1,th_score=6)\n","  obsrvr.inference()\n","  obsrvr.SaveVideo(save=True)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HYSiFgYX1l7A"},"source":["video_path is the address of the video in which we determine action recognition in video.\n","\n","pose_samples_folder is the address of csv file which we create in csv file notebook.\n","\n","DIC_ACT is terminal placed in a row if this occured we have one action\n","\n","in obsrvr.update(input_frame,second=1,th_score=6) we can determine specified intervals time in second arguman."]}]}